# AutoFlight
Deep Learning experimentation on Tello Drone.<br>
<img src = "https://github.com/mingweihe/AutoFlight/blob/master/screenshot/IMG_8626%202.JPG?raw=true" width='50%'><br>
Test screenshot<br>
<img src = "https://github.com/mingweihe/AutoFlight/blob/master/screenshot/screenshot2018-0703_14-03-47-235110.png?raw=true" width='50%'><br>
Training in jupyter<br>
<img src = "https://github.com/mingweihe/AutoFlight/blob/master/screenshot/screenshot2018-0703_18-31-34-560725.png?raw=true" width='50%'><br>
Terminal command:<br>
sudo python start.py checkpoints/cnnGesture15k_40epochs/ checkpoints/operation/
<br>
command parameters description:<br>
checkpoints/cnnGesture15k_40epochs/ is gesture checkpoints <br>
checkpoints/operation/ is autoflight checkpoint<br>
The reason I mix gesture and autoflight is I add a new cool feature which we can operate our drones with our hand signals.<br>
If you wanna use that feature, please refer to my another project:<br>
https://github.com/mingweihe/HandGestureRecognition
<br>
